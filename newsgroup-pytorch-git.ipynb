{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inspired by https://qiita.com/takeshikondo/items/419bebc4f9e6c78d5ea9\n",
    "# PyTorch code by fmireshg@eng.ucsd.edu\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from Model_20 import Model_20\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "11314\n",
      "    ***************  \n",
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n",
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
    "                                      categories=categories,)\n",
    "\n",
    "print (newsgroups_train.target_names)\n",
    "print (len(newsgroups_train.data))\n",
    "print(\"    ***************  \")\n",
    "#print (newsgroups_train.data[1])\n",
    "print((newsgroups_train.data[1]))\n",
    "print((categories[newsgroups_train.target[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 4308, 1350, 15, 11126, 38, 250, 29, 42, 298]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "labels=newsgroups_train.target\n",
    "texts = newsgroups_train.data\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "print (sequences[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134142 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "#print(word_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(11314, 1000)\n",
      "[  26 1835   14    1  816    3    1  726   17    9   44    8   88   27\n",
      "  171   39    4  828  273 1078 2908  198    3 2804  153   17  298    9\n",
      "  239  628   25  808  357   13   21   16   17  384  298  181  112  188\n",
      "  206 1498 1341    2   13   35   58 7860]\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(type(data))\n",
    "print (data.shape)\n",
    "print (data[0][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (11314, 1000)\n",
      "Shape of label tensor: (11314,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation to Training ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 11311 11312 11313]\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "print (indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6471  5451  6779 ... 10635  7867  1272]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(indices) \n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9052, 1000)\n",
      "(9052,)\n"
     ]
    }
   ],
   "source": [
    "data = data[indices] \n",
    "labels = labels[indices] \n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples] \n",
    "y_train = labels[:-nb_validation_samples] \n",
    "x_val = data[-nb_validation_samples:] \n",
    "y_val = labels[-nb_validation_samples:] \n",
    "\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "Download the pretrained embeddings from: https://www.kaggle.com/terenceliu4444/glove6b100dtxt\n",
    "\n",
    "To learn more about embeddings, have a look at https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "path = '/home/niloofar/'\n",
    "\n",
    "f = open(path+'glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    #values[-1] = values[-1].replace('\\n', '')\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    #print (values[1:])\n",
    "f.close()\n",
    " \n",
    "print ()\n",
    "print ('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134143, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "[0.93803958 0.71944306 0.34604118 0.01297138 0.03485201 0.71182131\n",
      " 0.57334824 0.88424407 0.71130049 0.6870206 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    #embedding_vector = embeddings_index[word]\n",
    "    if embedding_vector is not None:\n",
    "    # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print (embedding_matrix.shape)\n",
    "print (type(embedding_matrix))\n",
    "print (embedding_matrix[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_20(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dim, embeddings):\n",
    "        super(Model_20, self).__init__()\n",
    "        self.vocab_size = vocab_size \n",
    "        self.dim = dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.dim)\n",
    "        self.convnet = nn.Sequential(OrderedDict([\n",
    "            #('embed1', nn.Embedding(self.vocab_size, self.dim)),\n",
    "            ('c1', nn.ConvTranspose1d(100, 128, 5)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('maxpool1', nn.MaxPool1d(5)),\n",
    "            ('c2', nn.Conv1d(128, 128, 5)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('maxpool2', nn.MaxPool1d(5)),\n",
    "            ('c3', nn.Conv1d(128, 128, 5)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('maxpool3', nn.MaxPool1d(35)),\n",
    "        ]))\n",
    "    \n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(embeddings))\n",
    "        #copy_((embeddings))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "    \n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('f4', nn.Linear(128, 128)),\n",
    "            ('relu4', nn.ReLU()),\n",
    "            ('f5', nn.Linear(128, 20)),\n",
    "            ('sig5', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        \n",
    "        output = self.embedding(img)\n",
    "        output.transpose_(1,2)\n",
    "        output = self.convnet(output)\n",
    "        output = output.view(img.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model_20(embedding_matrix.shape[0], EMBEDDING_DIM, embedding_matrix)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    for i in range (0, x_train.shape[0], 128):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(torch.LongTensor(x_train[i:i+128, :]))\n",
    "        #print(torch.LongTensor(y_train[i:i+128]).shape)\n",
    "        loss = criterion(output, torch.LongTensor(y_train[i:i+128]))\n",
    "\n",
    "\n",
    "        print(loss)\n",
    "        print (\"____________________\")\n",
    "        #print(net.embedding.weight)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i in range (0, x_val.shape[0], 128):\n",
    "\n",
    "        output = net(torch.LongTensor(x_val[i:i+128, :]))\n",
    "        #avg_loss += criterion(output, y_val[i:i+128]).sum()\n",
    "        pred = output.detach().max(1)[1]\n",
    "        total_correct += pred.eq(torch.LongTensor(y_val[i:i+128]).view_as(pred)).sum()\n",
    "\n",
    "    #avg_loss /= len(data_test)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss, float(total_correct) / x_val.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9966, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9954, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9960, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9935, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9948, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9969, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(3.0014, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9939, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9951, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9940, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9940, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9877, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9888, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9968, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9972, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9901, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9908, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9893, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9974, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9868, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9906, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9849, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9897, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9869, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9946, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9903, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9927, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9950, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9946, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9858, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9834, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9866, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9892, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9926, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9819, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9903, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9917, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9928, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9935, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9975, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9941, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9883, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9913, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9782, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9752, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9841, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9876, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9941, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9802, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9813, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9842, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9851, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9841, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9698, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9735, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9814, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9799, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9895, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9710, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9835, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9833, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9792, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9677, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9681, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9818, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9698, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9661, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9752, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9864, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9767, grad_fn=<NllLossBackward>)\n",
      "____________________\n",
      "tensor(2.9687, grad_fn=<NllLossBackward>)\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    train(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An already traine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = Model_20(embedding_matrix.shape[0], EMBEDDING_DIM, embedding_matrix)\n",
    "\n",
    "net.load_state_dict(torch.load(\"20newsgroups-fixed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
